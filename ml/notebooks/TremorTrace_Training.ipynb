{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TremorTrace — Complete ML Training Pipeline\n",
    "\n",
    "**AI-powered Parkinson's disease screening using spiral and wave drawing analysis.**\n",
    "\n",
    "This notebook trains 2 MobileNetV2 CNNs (Spiral + Wave) using two-phase transfer learning,\n",
    "evaluates them comprehensively, and exports a production-ready inference package.\n",
    "\n",
    "**Models:** Spiral CNN (50%) + Wave CNN (50%) → Weighted Ensemble → Probability Percentage (0–100%)\n",
    "\n",
    "**Runtime:** Google Colab with T4 GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Environment setup: mount Drive, install deps, verify GPU, set seeds.\"\"\"\n",
    "import time\n",
    "cell_start = time.time()\n",
    "\n",
    "# Mount Google Drive for persistent storage\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Install requirements\n",
    "!pip install -q opendatasets scikit-learn seaborn opencv-python-headless\n",
    "\n",
    "# Core imports\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up project paths\n",
    "PROJECT_DIR = '/content/drive/MyDrive/TremorTrace'\n",
    "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
    "\n",
    "SAVE_DIR = os.path.join(PROJECT_DIR, 'outputs')\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.join(SAVE_DIR, 'plots'), exist_ok=True)\n",
    "\n",
    "# Clone or upload src/ to Colab — adjust this path to where your src/ lives\n",
    "# Option A: If src/ is in Google Drive\n",
    "SRC_DIR = os.path.join(PROJECT_DIR, 'src')\n",
    "if os.path.isdir(SRC_DIR):\n",
    "    sys.path.insert(0, os.path.dirname(SRC_DIR))\n",
    "    print(f'\\u2705 src/ found at {SRC_DIR}')\n",
    "else:\n",
    "    # Option B: Upload src/ files to /content/src/\n",
    "    SRC_DIR = '/content/src'\n",
    "    os.makedirs(SRC_DIR, exist_ok=True)\n",
    "    sys.path.insert(0, '/content')\n",
    "    print(f'\\u26a0\\ufe0f  src/ not in Drive. Upload src/ files to {SRC_DIR}')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Verify GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f'\\nTensorFlow version: {tf.__version__}')\n",
    "if gpus:\n",
    "    print(f'\\u2705 GPU available: {gpus[0].name}')\n",
    "    # Prevent TF from allocating all GPU memory at once\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "else:\n",
    "    print('\\u26a0\\ufe0f  No GPU detected! Training will be slow.')\n",
    "    print('   Go to Runtime > Change runtime type > Hardware accelerator > T4 GPU')\n",
    "\n",
    "print(f'\\n\\u2705 Environment setup complete ({time.time() - cell_start:.1f}s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Download Parkinson's Drawings dataset from Kaggle.\"\"\"\n",
    "cell_start = time.time()\n",
    "\n",
    "import opendatasets as od\n",
    "\n",
    "# Download dataset (will prompt for Kaggle credentials on first run)\n",
    "DATASET_URL = 'https://www.kaggle.com/datasets/kmader/parkinsons-drawings'\n",
    "DOWNLOAD_DIR = '/content'\n",
    "od.download(DATASET_URL, data_dir=DOWNLOAD_DIR)\n",
    "\n",
    "# Set data paths\n",
    "DATA_ROOT = os.path.join(DOWNLOAD_DIR, 'parkinsons-drawings')\n",
    "\n",
    "# Update config\n",
    "from src import config\n",
    "config.DATA_ROOT = DATA_ROOT\n",
    "config.PROJECT_DIR = PROJECT_DIR\n",
    "\n",
    "# Verify dataset structure\n",
    "assert os.path.isdir(DATA_ROOT), f'Dataset not found at {DATA_ROOT}'\n",
    "print(f'\\n\\u2705 Dataset downloaded to: {DATA_ROOT}')\n",
    "print(f'   Contents: {os.listdir(DATA_ROOT)}')\n",
    "print(f'   ({time.time() - cell_start:.1f}s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Explore dataset structure: count images per class per split.\"\"\"\n",
    "\n",
    "# Define paths for each drawing type\n",
    "PATHS = {}\n",
    "for drawing_type in ['spiral', 'wave']:\n",
    "    PATHS[drawing_type] = {\n",
    "        'train': os.path.join(DATA_ROOT, drawing_type, 'training'),\n",
    "        'test': os.path.join(DATA_ROOT, drawing_type, 'testing'),\n",
    "    }\n",
    "\n",
    "# Count images per class per split\n",
    "print('=' * 65)\n",
    "print(f'{\"Drawing\":>10} | {\"Split\":>8} | {\"Healthy\":>8} | {\"Parkinson\":>10} | {\"Total\":>6}')\n",
    "print('=' * 65)\n",
    "\n",
    "total_images = 0\n",
    "for drawing_type in ['spiral', 'wave']:\n",
    "    for split_name, split_path in PATHS[drawing_type].items():\n",
    "        healthy_dir = os.path.join(split_path, 'healthy')\n",
    "        parkinson_dir = os.path.join(split_path, 'parkinson')\n",
    "\n",
    "        n_healthy = len([f for f in os.listdir(healthy_dir)\n",
    "                         if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "        n_parkinson = len([f for f in os.listdir(parkinson_dir)\n",
    "                           if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "        n_total = n_healthy + n_parkinson\n",
    "        total_images += n_total\n",
    "\n",
    "        print(f'{drawing_type:>10} | {split_name:>8} | {n_healthy:>8} | {n_parkinson:>10} | {n_total:>6}')\n",
    "\n",
    "print('=' * 65)\n",
    "print(f'{\"TOTAL\":>10} | {\"\":>8} | {\"\":>8} | {\"\":>10} | {total_images:>6}')\n",
    "print(f'\\n\\u2705 Dataset exploration complete — {total_images} total images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Visualize sample images: 4x5 grid of spiral/wave × healthy/parkinson.\"\"\"\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "categories = [\n",
    "    ('spiral', 'healthy',   'Spiral — Healthy'),\n",
    "    ('spiral', 'parkinson', 'Spiral — Parkinson'),\n",
    "    ('wave',   'healthy',   'Wave — Healthy'),\n",
    "    ('wave',   'parkinson', 'Wave — Parkinson'),\n",
    "]\n",
    "\n",
    "n_samples = 5\n",
    "fig, axes = plt.subplots(4, n_samples, figsize=(20, 16))\n",
    "fig.suptitle('Dataset Samples', fontsize=20, fontweight='bold')\n",
    "\n",
    "for row, (drawing_type, class_name, row_label) in enumerate(categories):\n",
    "    img_dir = os.path.join(PATHS[drawing_type]['train'], class_name)\n",
    "    img_files = sorted([f for f in os.listdir(img_dir)\n",
    "                        if f.lower().endswith(('.png', '.jpg', '.jpeg'))])[:n_samples]\n",
    "\n",
    "    for col, img_file in enumerate(img_files):\n",
    "        img = PILImage.open(os.path.join(img_dir, img_file)).convert('RGB')\n",
    "        axes[row, col].imshow(img)\n",
    "        axes[row, col].axis('off')\n",
    "        if col == 0:\n",
    "            axes[row, col].set_ylabel(row_label, fontsize=12, fontweight='bold',\n",
    "                                       rotation=0, labelpad=120, va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(SAVE_DIR, 'plots', 'dataset_samples.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('\\u2705 Sample visualization complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Create Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create train/val/test generators for both spiral and wave.\"\"\"\n",
    "from src.data_pipeline import create_generators\n",
    "\n",
    "print('Creating Spiral generators...')\n",
    "spiral_train_gen, spiral_val_gen, spiral_test_gen = create_generators(\n",
    "    'spiral',\n",
    "    PATHS['spiral']['train'],\n",
    "    PATHS['spiral']['test'],\n",
    ")\n",
    "\n",
    "print('\\nCreating Wave generators...')\n",
    "wave_train_gen, wave_val_gen, wave_test_gen = create_generators(\n",
    "    'wave',\n",
    "    PATHS['wave']['train'],\n",
    "    PATHS['wave']['test'],\n",
    ")\n",
    "\n",
    "print('\\n\\u2705 All data generators created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Verify Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Visualize augmentation effects on spiral and wave images.\"\"\"\n",
    "from src.data_pipeline import get_augmentation_config\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "\n",
    "n_augmented = 6\n",
    "fig, axes = plt.subplots(2, n_augmented + 1, figsize=(20, 6))\n",
    "fig.suptitle('Augmentation Verification', fontsize=18, fontweight='bold')\n",
    "\n",
    "for row, drawing_type in enumerate(['spiral', 'wave']):\n",
    "    # Pick the first training image\n",
    "    class_dir = os.path.join(PATHS[drawing_type]['train'], 'healthy')\n",
    "    img_file = sorted(os.listdir(class_dir))[0]\n",
    "    img_path = os.path.join(class_dir, img_file)\n",
    "\n",
    "    img = load_img(img_path, target_size=(224, 224))\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "\n",
    "    # Show original\n",
    "    axes[row, 0].imshow(img_array)\n",
    "    axes[row, 0].set_title('Original', fontsize=10, fontweight='bold')\n",
    "    axes[row, 0].set_ylabel(f'{drawing_type.capitalize()}', fontsize=12, fontweight='bold')\n",
    "    axes[row, 0].axis('off')\n",
    "\n",
    "    # Generate augmented versions\n",
    "    aug_config = get_augmentation_config(drawing_type)\n",
    "    aug_config_no_rescale = {k: v for k, v in aug_config.items() if k != 'rescale'}\n",
    "    datagen = ImageDataGenerator(**aug_config_no_rescale)\n",
    "\n",
    "    img_batch = img_array[np.newaxis, ...]  # Add batch dim\n",
    "    aug_iter = datagen.flow(img_batch, batch_size=1, seed=None)\n",
    "\n",
    "    for col in range(1, n_augmented + 1):\n",
    "        aug_img = next(aug_iter)[0]\n",
    "        aug_img = np.clip(aug_img, 0, 1)\n",
    "        axes[row, col].imshow(aug_img)\n",
    "        axes[row, col].set_title(f'Aug {col}', fontsize=10)\n",
    "        axes[row, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(SAVE_DIR, 'plots', 'augmentation_verification.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('\\u2705 Augmentation verification complete')\n",
    "print('   Spiral: 360° rotation (rotationally invariant)')\n",
    "print('   Wave: 15° rotation + horizontal flip (orientation-sensitive)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Build MobileNetV2 models for spiral and wave classification.\"\"\"\n",
    "from src.model_builder import build_model\n",
    "\n",
    "print('Building Spiral CNN...')\n",
    "spiral_model, spiral_base = build_model('spiral')\n",
    "\n",
    "print('\\nBuilding Wave CNN...')\n",
    "wave_model, wave_base = build_model('wave')\n",
    "\n",
    "# Print architecture summary (both models are identical in structure)\n",
    "print('\\n' + '=' * 60)\n",
    "print('Model Architecture (identical for both):')\n",
    "print('=' * 60)\n",
    "spiral_model.summary()\n",
    "\n",
    "print('\\n\\u2705 Both models built and compiled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Train Spiral CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train Spiral CNN with two-phase transfer learning.\"\"\"\n",
    "from src.trainer import train_two_phase\n",
    "\n",
    "spiral_history = train_two_phase(\n",
    "    model=spiral_model,\n",
    "    base_model=spiral_base,\n",
    "    train_gen=spiral_train_gen,\n",
    "    val_gen=spiral_val_gen,\n",
    "    name='spiral',\n",
    "    save_dir=SAVE_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Train Wave CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train Wave CNN with two-phase transfer learning.\"\"\"\n",
    "\n",
    "wave_history = train_two_phase(\n",
    "    model=wave_model,\n",
    "    base_model=wave_base,\n",
    "    train_gen=wave_train_gen,\n",
    "    val_gen=wave_val_gen,\n",
    "    name='wave',\n",
    "    save_dir=SAVE_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Visualize training curves for both models.\"\"\"\n",
    "from src.evaluator import plot_training_history\n",
    "\n",
    "print('Spiral CNN Training History:')\n",
    "plot_training_history(spiral_history, 'Spiral CNN', SAVE_DIR)\n",
    "\n",
    "print('\\nWave CNN Training History:')\n",
    "plot_training_history(wave_history, 'Wave CNN', SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11: Evaluate Both CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Full evaluation suite for both models.\"\"\"\n",
    "from src.evaluator import evaluate_model, plot_prediction_distribution\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Evaluate Spiral CNN\n",
    "print('\\n' + '=' * 60)\n",
    "print('EVALUATING SPIRAL CNN')\n",
    "print('=' * 60)\n",
    "spiral_pred, spiral_true, spiral_acc, spiral_auc = evaluate_model(\n",
    "    spiral_model, spiral_test_gen, 'Spiral CNN', SAVE_DIR\n",
    ")\n",
    "plot_prediction_distribution(spiral_pred, spiral_true, 'Spiral CNN', SAVE_DIR)\n",
    "\n",
    "# Evaluate Wave CNN\n",
    "print('\\n' + '=' * 60)\n",
    "print('EVALUATING WAVE CNN')\n",
    "print('=' * 60)\n",
    "wave_pred, wave_true, wave_acc, wave_auc = evaluate_model(\n",
    "    wave_model, wave_test_gen, 'Wave CNN', SAVE_DIR\n",
    ")\n",
    "plot_prediction_distribution(wave_pred, wave_true, 'Wave CNN', SAVE_DIR)\n",
    "\n",
    "# Compute additional metrics for comparison\n",
    "spiral_prec = precision_score(spiral_true, (spiral_pred > 0.5).astype(int), zero_division=0)\n",
    "spiral_rec = recall_score(spiral_true, (spiral_pred > 0.5).astype(int), zero_division=0)\n",
    "wave_prec = precision_score(wave_true, (wave_pred > 0.5).astype(int), zero_division=0)\n",
    "wave_rec = recall_score(wave_true, (wave_pred > 0.5).astype(int), zero_division=0)\n",
    "\n",
    "# Store metrics for later use\n",
    "all_metrics = {\n",
    "    'Spiral CNN': {\n",
    "        'accuracy': spiral_acc,\n",
    "        'auc': spiral_auc,\n",
    "        'precision': spiral_prec,\n",
    "        'recall': spiral_rec,\n",
    "    },\n",
    "    'Wave CNN': {\n",
    "        'accuracy': wave_acc,\n",
    "        'auc': wave_auc,\n",
    "        'precision': wave_prec,\n",
    "        'recall': wave_rec,\n",
    "    },\n",
    "}\n",
    "\n",
    "print('\\n\\u2705 Both models evaluated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 12: Sample Predictions with Percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Visual grid showing predictions as percentages with risk tiers.\"\"\"\n",
    "from src.evaluator import show_sample_predictions\n",
    "\n",
    "print('Spiral CNN — Sample Predictions:')\n",
    "show_sample_predictions(spiral_model, spiral_test_gen, 'Spiral CNN', SAVE_DIR)\n",
    "\n",
    "print('\\nWave CNN — Sample Predictions:')\n",
    "show_sample_predictions(wave_model, wave_test_gen, 'Wave CNN', SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 13: Grad-CAM Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Generate Grad-CAM heatmaps showing what each model focuses on.\"\"\"\n",
    "from src.gradcam import visualize_gradcam_grid\n",
    "\n",
    "print('Spiral CNN — Grad-CAM:')\n",
    "visualize_gradcam_grid(spiral_model, spiral_test_gen, 'Spiral CNN', SAVE_DIR, n_samples=8)\n",
    "\n",
    "print('\\nWave CNN — Grad-CAM:')\n",
    "visualize_gradcam_grid(wave_model, wave_test_gen, 'Wave CNN', SAVE_DIR, n_samples=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 14: Test Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Test the 2-model ensemble on matched spiral/wave test samples.\"\"\"\n",
    "from src.ensemble import ensemble_predict\n",
    "import json\n",
    "\n",
    "# Get predictions from both models on their respective test sets\n",
    "# Since spiral and wave test sets have the same number of samples in matching order,\n",
    "# we can pair them for ensemble testing\n",
    "n_ensemble_samples = min(len(spiral_pred), len(wave_pred))\n",
    "\n",
    "print('=' * 80)\n",
    "print(f'{\"#\":>3} | {\"Spiral %\":>9} | {\"Wave %\":>7} | {\"Ensemble %\":>10} | {\"Risk Tier\":>15} | {\"Agree\":>5}')\n",
    "print('=' * 80)\n",
    "\n",
    "ensemble_results = []\n",
    "for i in range(n_ensemble_samples):\n",
    "    result = ensemble_predict(\n",
    "        spiral_cnn_prob=float(spiral_pred[i]),\n",
    "        wave_cnn_prob=float(wave_pred[i]),\n",
    "        input_mode='drawn',\n",
    "    )\n",
    "    ensemble_results.append(result)\n",
    "\n",
    "    print(f'{i+1:>3} | {result[\"spiral_cnn_percent\"]:>8.1f}% | {result[\"wave_cnn_percent\"]:>6.1f}% | '\n",
    "          f'{result[\"pd_probability_percent\"]:>9.1f}% | {result[\"risk_tier\"]:>15} | '\n",
    "          f'{\"Yes\" if result[\"unanimous\"] else \"No\":>5}')\n",
    "\n",
    "# Show a few full result dictionaries\n",
    "print('\\n' + '=' * 80)\n",
    "print('Sample Full Output (first 3):')\n",
    "print('=' * 80)\n",
    "for i in range(min(3, len(ensemble_results))):\n",
    "    # Exclude disclaimer from print for brevity\n",
    "    display_result = {k: v for k, v in ensemble_results[i].items() if k != 'disclaimer'}\n",
    "    print(f'\\nSample {i+1}:')\n",
    "    print(json.dumps(display_result, indent=2))\n",
    "\n",
    "print(f'\\n\\u2705 Ensemble tested on {n_ensemble_samples} paired samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 15: Risk Tier Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Visualize how predictions distribute across risk tiers.\"\"\"\n",
    "from src.evaluator import plot_risk_tier_distribution\n",
    "\n",
    "print('Spiral CNN — Risk Tier Distribution:')\n",
    "plot_risk_tier_distribution(spiral_pred, spiral_true, 'Spiral CNN', SAVE_DIR)\n",
    "\n",
    "print('\\nWave CNN — Risk Tier Distribution:')\n",
    "plot_risk_tier_distribution(wave_pred, wave_true, 'Wave CNN', SAVE_DIR)\n",
    "\n",
    "# Ensemble risk tier distribution\n",
    "print('\\nEnsemble — Risk Tier Distribution:')\n",
    "ensemble_probs = np.array([\n",
    "    0.5 * spiral_pred[i] + 0.5 * wave_pred[i]\n",
    "    for i in range(n_ensemble_samples)\n",
    "])\n",
    "# Use spiral_true as ground truth (same for both since test sets are aligned)\n",
    "plot_risk_tier_distribution(ensemble_probs, spiral_true[:n_ensemble_samples], 'Ensemble', SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 16: Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Side-by-side comparison of Spiral CNN vs Wave CNN.\"\"\"\n",
    "from src.evaluator import plot_model_comparison\n",
    "\n",
    "print('Model Comparison — Spiral CNN vs Wave CNN:')\n",
    "print(f'  Spiral CNN: Accuracy={spiral_acc:.1%}, AUC={spiral_auc:.4f}')\n",
    "print(f'  Wave CNN:   Accuracy={wave_acc:.1%}, AUC={wave_auc:.4f}')\n",
    "\n",
    "plot_model_comparison(all_metrics, SAVE_DIR)\n",
    "\n",
    "print('\\n\\u2705 Model comparison complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 17: Test Input Handler End-to-End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"End-to-end test of process_input() — the single backend entry point.\"\"\"\n",
    "import base64\n",
    "from src.input_handler import process_input, preprocess_image_from_base64\n",
    "\n",
    "# Pick one spiral and one wave test image, encode as base64\n",
    "spiral_test_dir = os.path.join(PATHS['spiral']['test'], 'parkinson')\n",
    "wave_test_dir = os.path.join(PATHS['wave']['test'], 'parkinson')\n",
    "\n",
    "spiral_img_path = os.path.join(spiral_test_dir, sorted(os.listdir(spiral_test_dir))[0])\n",
    "wave_img_path = os.path.join(wave_test_dir, sorted(os.listdir(wave_test_dir))[0])\n",
    "\n",
    "# Encode images to base64 (simulating what the frontend sends)\n",
    "with open(spiral_img_path, 'rb') as f:\n",
    "    spiral_b64 = base64.b64encode(f.read()).decode('utf-8')\n",
    "with open(wave_img_path, 'rb') as f:\n",
    "    wave_b64 = base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "# Test \"drawn\" mode\n",
    "print('Testing process_input() with input_mode=\"drawn\"...')\n",
    "result_drawn = process_input(\n",
    "    spiral_image_base64=spiral_b64,\n",
    "    wave_image_base64=wave_b64,\n",
    "    spiral_cnn_model=spiral_model,\n",
    "    wave_cnn_model=wave_model,\n",
    "    input_mode='drawn',\n",
    ")\n",
    "\n",
    "# Test \"uploaded\" mode (should produce identical predictions)\n",
    "print('Testing process_input() with input_mode=\"uploaded\"...')\n",
    "result_uploaded = process_input(\n",
    "    spiral_image_base64=spiral_b64,\n",
    "    wave_image_base64=wave_b64,\n",
    "    spiral_cnn_model=spiral_model,\n",
    "    wave_cnn_model=wave_model,\n",
    "    input_mode='uploaded',\n",
    ")\n",
    "\n",
    "# Display results (excluding base64 fields for readability)\n",
    "def display_result(result, label):\n",
    "    print(f'\\n{\"=\" * 60}')\n",
    "    print(f'{label}')\n",
    "    print(f'{\"=\" * 60}')\n",
    "    for key, value in result.items():\n",
    "        if 'base64' in key:\n",
    "            print(f'  {key}: [{\"present\" if value else \"missing\"}, '\n",
    "                  f'{len(value) if value else 0} chars]')\n",
    "        elif key == 'disclaimer':\n",
    "            print(f'  {key}: \"{value[:50]}...\"')\n",
    "        else:\n",
    "            print(f'  {key}: {value}')\n",
    "\n",
    "display_result(result_drawn, 'Result — Drawn Mode')\n",
    "display_result(result_uploaded, 'Result — Uploaded Mode')\n",
    "\n",
    "# Verify both modes produce the same predictions\n",
    "assert result_drawn['pd_probability_percent'] == result_uploaded['pd_probability_percent'], \\\n",
    "    'ERROR: Drawn and uploaded modes produced different predictions!'\n",
    "print(f'\\n\\u2705 Both modes produce identical predictions: '\n",
    "      f'{result_drawn[\"pd_probability_percent\"]}% ({result_drawn[\"risk_tier\"]})')\n",
    "\n",
    "# Display Grad-CAM overlays\n",
    "if result_drawn.get('spiral_gradcam_base64') and result_drawn.get('wave_gradcam_base64'):\n",
    "    from IPython.display import HTML, display\n",
    "    display(HTML(f'''\n",
    "    <div style=\"display: flex; gap: 20px;\">\n",
    "        <div><h4>Spiral Grad-CAM</h4>\n",
    "            <img src=\"{result_drawn['spiral_gradcam_base64']}\" width=\"224\"/></div>\n",
    "        <div><h4>Wave Grad-CAM</h4>\n",
    "            <img src=\"{result_drawn['wave_gradcam_base64']}\" width=\"224\"/></div>\n",
    "    </div>\n",
    "    '''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 18: Export Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Export models and inference files for backend integration.\"\"\"\n",
    "import shutil\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "EXPORT_DIR = os.path.join(PROJECT_DIR, 'exports')\n",
    "os.makedirs(EXPORT_DIR, exist_ok=True)\n",
    "\n",
    "print('Exporting TremorTrace package...')\n",
    "print('=' * 60)\n",
    "\n",
    "# 1. Copy trained models\n",
    "for model_name in ['spiral', 'wave']:\n",
    "    src_path = os.path.join(SAVE_DIR, f'{model_name}_final.keras')\n",
    "    dst_path = os.path.join(EXPORT_DIR, f'{model_name}_final.keras')\n",
    "    if os.path.exists(src_path):\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "        size_mb = os.path.getsize(dst_path) / (1024 * 1024)\n",
    "        print(f'  \\u2705 {model_name}_final.keras ({size_mb:.1f} MB)')\n",
    "    else:\n",
    "        print(f'  \\u26a0\\ufe0f  {model_name}_final.keras not found at {src_path}')\n",
    "\n",
    "# 2. Copy backend inference files (self-contained)\n",
    "backend_files = ['ensemble.py', 'gradcam.py', 'input_handler.py']\n",
    "for filename in backend_files:\n",
    "    src_path = os.path.join(SRC_DIR, filename)\n",
    "    dst_path = os.path.join(EXPORT_DIR, filename)\n",
    "    if os.path.exists(src_path):\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "        print(f'  \\u2705 {filename}')\n",
    "    else:\n",
    "        print(f'  \\u26a0\\ufe0f  {filename} not found at {src_path}')\n",
    "\n",
    "# 3. Save metadata JSON\n",
    "metadata = {\n",
    "    'project': 'TremorTrace',\n",
    "    'version': '1.0.0',\n",
    "    'exported_at': datetime.now().isoformat(),\n",
    "    'models': {\n",
    "        'spiral_cnn': {\n",
    "            'file': 'spiral_final.keras',\n",
    "            'architecture': 'MobileNetV2 + classification head',\n",
    "            'input_shape': [224, 224, 3],\n",
    "            'accuracy': round(spiral_acc, 4),\n",
    "            'auc': round(spiral_auc, 4),\n",
    "        },\n",
    "        'wave_cnn': {\n",
    "            'file': 'wave_final.keras',\n",
    "            'architecture': 'MobileNetV2 + classification head',\n",
    "            'input_shape': [224, 224, 3],\n",
    "            'accuracy': round(wave_acc, 4),\n",
    "            'auc': round(wave_auc, 4),\n",
    "        },\n",
    "    },\n",
    "    'ensemble': {\n",
    "        'weights': {'spiral_cnn': 0.5, 'wave_cnn': 0.5},\n",
    "        'output': 'probability_percentage_0_to_100',\n",
    "    },\n",
    "    'risk_tiers': [\n",
    "        {'range': '0-25%', 'label': 'Low Risk', 'color': '#27AE60'},\n",
    "        {'range': '25-45%', 'label': 'Mild Risk', 'color': '#F1C40F'},\n",
    "        {'range': '45-65%', 'label': 'Moderate Risk', 'color': '#E67E22'},\n",
    "        {'range': '65-85%', 'label': 'Elevated Risk', 'color': '#E74C3C'},\n",
    "        {'range': '85-100%', 'label': 'High Risk', 'color': '#C0392B'},\n",
    "    ],\n",
    "    'entry_point': 'input_handler.process_input()',\n",
    "    'backend_files': backend_files,\n",
    "}\n",
    "\n",
    "metadata_path = os.path.join(EXPORT_DIR, 'metadata.json')\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(f'  \\u2705 metadata.json')\n",
    "\n",
    "print(f'\\n\\u2705 Export complete! Package at: {EXPORT_DIR}')\n",
    "print(f'   Files: {os.listdir(EXPORT_DIR)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 19: Final Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Final summary dashboard with all key metrics and visualizations.\"\"\"\n",
    "from src.gradcam import generate_gradcam, find_target_layer\n",
    "from src.ensemble import get_risk_tier\n",
    "\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "fig.suptitle('TremorTrace — Final Dashboard', fontsize=22, fontweight='bold')\n",
    "\n",
    "# Grid: 2 rows x 3 columns\n",
    "gs = fig.add_gridspec(2, 3, hspace=0.35, wspace=0.3)\n",
    "\n",
    "# --- Panel 1: Model Metrics Table ---\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax1.axis('off')\n",
    "ax1.set_title('Model Performance', fontsize=14, fontweight='bold')\n",
    "\n",
    "table_data = [\n",
    "    ['Metric', 'Spiral CNN', 'Wave CNN'],\n",
    "    ['Accuracy', f'{spiral_acc:.1%}', f'{wave_acc:.1%}'],\n",
    "    ['AUC', f'{spiral_auc:.4f}', f'{wave_auc:.4f}'],\n",
    "    ['Precision', f'{spiral_prec:.4f}', f'{wave_prec:.4f}'],\n",
    "    ['Recall', f'{spiral_rec:.4f}', f'{wave_rec:.4f}'],\n",
    "]\n",
    "table = ax1.table(cellText=table_data[1:], colLabels=table_data[0],\n",
    "                  cellLoc='center', loc='center')\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(1, 1.5)\n",
    "for i in range(3):\n",
    "    table[0, i].set_facecolor('#3498DB')\n",
    "    table[0, i].set_text_props(color='white', fontweight='bold')\n",
    "\n",
    "# --- Panel 2: Spiral Grad-CAM sample ---\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "spiral_test_gen.reset()\n",
    "sample_batch, _ = next(spiral_test_gen)\n",
    "sample_img = sample_batch[0]\n",
    "_, spiral_overlay = generate_gradcam(spiral_model, sample_img)\n",
    "ax2.imshow(spiral_overlay)\n",
    "ax2.set_title('Spiral CNN — Grad-CAM', fontsize=14, fontweight='bold')\n",
    "ax2.axis('off')\n",
    "\n",
    "# --- Panel 3: Wave Grad-CAM sample ---\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "wave_test_gen.reset()\n",
    "sample_batch, _ = next(wave_test_gen)\n",
    "sample_img = sample_batch[0]\n",
    "_, wave_overlay = generate_gradcam(wave_model, sample_img)\n",
    "ax3.imshow(wave_overlay)\n",
    "ax3.set_title('Wave CNN — Grad-CAM', fontsize=14, fontweight='bold')\n",
    "ax3.axis('off')\n",
    "\n",
    "# --- Panel 4: Ensemble Agreement Stats ---\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "ax4.axis('off')\n",
    "ax4.set_title('Ensemble Statistics', fontsize=14, fontweight='bold')\n",
    "\n",
    "n_unanimous = sum(1 for r in ensemble_results if r['unanimous'])\n",
    "n_split = len(ensemble_results) - n_unanimous\n",
    "avg_confidence = np.mean([r['confidence_score'] for r in ensemble_results])\n",
    "\n",
    "stats_text = (\n",
    "    f'Total test samples: {len(ensemble_results)}\\n'\n",
    "    f'Models unanimous: {n_unanimous} ({n_unanimous/len(ensemble_results):.0%})\\n'\n",
    "    f'Models split: {n_split} ({n_split/len(ensemble_results):.0%})\\n'\n",
    "    f'Avg confidence: {avg_confidence:.3f}\\n'\n",
    "    f'Ensemble weights: 50/50'\n",
    ")\n",
    "ax4.text(0.1, 0.5, stats_text, transform=ax4.transAxes,\n",
    "         fontsize=12, verticalalignment='center', fontfamily='monospace',\n",
    "         bbox=dict(boxstyle='round', facecolor='#ECF0F1', alpha=0.8))\n",
    "\n",
    "# --- Panel 5: Risk Tier Pie Chart ---\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "from src.config import RISK_TIERS\n",
    "\n",
    "ensemble_pcts = [r['pd_probability_percent'] for r in ensemble_results]\n",
    "tier_counts = []\n",
    "tier_labels_list = []\n",
    "tier_colors_list = []\n",
    "for lower, upper, label, color in RISK_TIERS:\n",
    "    count = sum(1 for p in ensemble_pcts if lower <= p < upper or (upper == 100 and p == 100))\n",
    "    if count > 0:\n",
    "        tier_counts.append(count)\n",
    "        tier_labels_list.append(f'{label}\\n({count})')\n",
    "        tier_colors_list.append(color)\n",
    "\n",
    "if tier_counts:\n",
    "    ax5.pie(tier_counts, labels=tier_labels_list, colors=tier_colors_list,\n",
    "            autopct='%1.0f%%', startangle=90, textprops={'fontsize': 10})\n",
    "ax5.set_title('Ensemble Risk Tier Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# --- Panel 6: Architecture Summary ---\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "ax6.axis('off')\n",
    "ax6.set_title('Architecture', fontsize=14, fontweight='bold')\n",
    "\n",
    "arch_text = (\n",
    "    'TremorTrace Pipeline\\n'\n",
    "    '\\u2500' * 25 + '\\n'\n",
    "    'Input: 2 drawings (spiral + wave)\\n'\n",
    "    '\\u2193\\n'\n",
    "    'Spiral CNN (MobileNetV2) \\u2192 50%\\n'\n",
    "    'Wave CNN (MobileNetV2)   \\u2192 50%\\n'\n",
    "    '\\u2193\\n'\n",
    "    'Weighted Ensemble\\n'\n",
    "    '\\u2193\\n'\n",
    "    'PD Probability (0\\u2013100%)\\n'\n",
    "    '+ Risk Tier + Grad-CAM'\n",
    ")\n",
    "ax6.text(0.1, 0.5, arch_text, transform=ax6.transAxes,\n",
    "         fontsize=11, verticalalignment='center', fontfamily='monospace',\n",
    "         bbox=dict(boxstyle='round', facecolor='#ECF0F1', alpha=0.8))\n",
    "\n",
    "plt.savefig(os.path.join(SAVE_DIR, 'plots', 'final_dashboard.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('\\u2705 TremorTrace ML Pipeline Complete!')\n",
    "print('=' * 60)\n",
    "print(f'  Spiral CNN: Accuracy={spiral_acc:.1%}, AUC={spiral_auc:.4f}')\n",
    "print(f'  Wave CNN:   Accuracy={wave_acc:.1%}, AUC={wave_auc:.4f}')\n",
    "print(f'  Export dir: {EXPORT_DIR}')\n",
    "print(f'  Plots dir:  {os.path.join(SAVE_DIR, \"plots\")}')\n",
    "print('\\n  Next steps:')\n",
    "print('  1. Download exports/ folder for backend integration')\n",
    "print('  2. See exports/README.md for integration instructions')\n",
    "print('  3. Backend calls input_handler.process_input() — that\\'s it!')\n",
    "print('=' * 60)"
   ]
  }
 ]
}
